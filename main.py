import cv2
import numpy as np
import easyocr
import re
import pandas as pd
import FinanceDataReader as fdr
import Levenshtein
import os
import json
from tkinter import Tk, filedialog

# ==========================================
# [ê³µí†µ] ìƒì¥ì‚¬ ë° OCR ì´ˆê¸°í™”
# ==========================================
print("ğŸ“¢ ìƒì¥ì‚¬ ëª©ë¡ ë¡œë“œ ì¤‘...")
try: krx_names = fdr.StockListing("KRX")["Name"].tolist()
except: krx_names = []

reader = easyocr.Reader(['ko', 'en'], gpu=False)

# [ìëª¨ ë¶„í•´ í•¨ìˆ˜]
def h2j(text):
    CHO = ['ã„±','ã„²','ã„´','ã„·','ã„¸','ã„¹','ã…','ã…‚','ã…ƒ','ã……','ã…†','ã…‡','ã…ˆ','ã…‰','ã…Š','ã…‹','ã…Œ','ã…','ã…']
    JUNG = ['ã…','ã…','ã…‘','ã…’','ã…“','ã…”','ã…•','ã…–','ã…—','ã…˜','ã…™','ã…š','ã…›','ã…œ','ã…','ã…','ã…Ÿ','ã… ','ã…¡','ã…¢','ã…£']
    JONG = ['','ã„±','ã„²','ã„³','ã„´','ã„µ','ã„¶','ã„·','ã„¹','ã„º','ã„»','ã„¼','ã„½','ã„¾','ã„¿','ã…€','ã…','ã…‚','ã…„','ã……','ã…†','ã…‡','ã…ˆ','ã…Š','ã…‹','ã…Œ','ã…','ã…']
    res = ""
    for c in text:
        if 'ê°€' <= c <= 'í£':
            code = ord(c) - ord('ê°€')
            res += CHO[code//588] + JUNG[(code//28)%21] + JONG[code%28]
        else: res += c
    return res

# ==========================================
# [ë¡œì§ 1] ì¢…ëª© ë³´ì • ì—”ì§„ (Microscopic)
# ==========================================
def microscopic_correct_stock(n):
    n_clean = re.sub(r'[0-9]', '', n).upper().replace(" ", "")
    if not n_clean or n_clean in krx_names: return n_clean
    n_comp = h2j(n_clean)
    candidates = []
    for s in krx_names:
        s_comp = h2j(s)
        if abs(len(s) - len(n_clean)) <= 2:
            dist = Levenshtein.distance(n_comp, s_comp)
            sim = 1 - (dist / max(len(n_comp), len(s_comp)) if max(len(n_comp), len(s_comp)) > 0 else 1)
            if s.startswith(n_clean[0]): sim += 0.2
            candidates.append((s, sim))
    candidates.sort(key=lambda x: x[1], reverse=True)
    return candidates[0][0] if candidates and candidates[0][1] >= 0.52 else n_clean

# ==========================================
# [ë¡œì§ 2] í…Œë§ˆ ë³´ì • ì—”ì§„ (Pool)
# ==========================================
THEME_POOL = ["ë¡œë´‡","ë°˜ë„ì²´","ë°”ì´ì˜¤","ìë™ì°¨","2ì°¨ì „ì§€","AI","ìš°ì£¼í•­ê³µ","ë°©ì‚°","ì‹ ì•½ê°œë°œ","ììœ¨ì£¼í–‰"] # ìœ„ì— ì£¼ì‹  ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©

def correct_theme_from_pool(raw):
    clean = re.sub(r'[^ê°€-í£A-Z0-9]', '', raw.upper())
    if len(clean) < 2: return None
    if clean in THEME_POOL: return clean
    cj = h2j(clean)
    best, best_sim = None, 0
    for t in THEME_POOL:
        tj = h2j(t.upper())
        sim = 1 - (Levenshtein.distance(cj, tj) / max(len(cj), len(tj)))
        if t.startswith(clean[:1]): sim += 0.2
        if sim > best_sim: best_sim, best = sim, t
    return best if best_sim >= 0.5 else None

# ==========================================
# [í†µí•© ë¶„ì„] ì‚¬ì§„ í•œ ì¥ìœ¼ë¡œ ë‘ ë¡œì§ ë”°ë¡œ ëŒë¦¬ê¸°
# ==========================================
def run_integrated_analysis():
    root = Tk(); root.withdraw(); img_path = filedialog.askopenfilename(); root.destroy()
    if not img_path: return
    img = cv2.imread(img_path)

    # --- 1. í…Œë§ˆ ë¶„ì„ (ë…¸ë€ìƒ‰ ë§ˆìŠ¤í¬ ë¡œì§) ---
    print("ğŸ¨ [STEP 1] í…Œë§ˆ ë¶„ì„ ì¤‘...")
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, (15,70,120), (45,255,255))
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    theme_locations = []
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w < 30 or h < 8: continue
        roi = cv2.resize(img[y:y+h, x:x+w], None, fx=3, fy=3)
        raw_theme = "".join(reader.readtext(roi, detail=0))
        fixed_theme = correct_theme_from_pool(raw_theme)
        if fixed_theme:
            theme_locations.append({'name': fixed_theme, 'x': x, 'y': y})

    # --- 2. ì¢…ëª© ë¶„ì„ (ê¸°ë‘¥ ë° í–‰ ë¶„ì„ ë¡œì§) ---
    print("ğŸ” [STEP 2] ì¢…ëª© ë¶„ì„ ì¤‘...")
    img_res = cv2.resize(cv2.convertScaleAbs(img, alpha=1.5), None, fx=3.5, fy=3.5, interpolation=cv2.INTER_LANCZOS4)
    thresh = cv2.adaptiveThreshold(cv2.cvtColor(img_res, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 10)
    
    mapping_result = {}
    col_w = img_res.shape[1] // 4
    
    for i in range(4): # 4ê°œ ê¸°ë‘¥ ë¶„ì„
        c_start, c_end = i * col_w, (i + 1) * col_w
        # í•´ë‹¹ ê¸°ë‘¥ì— ì†í•œ í…Œë§ˆ ì°¾ê¸°
        current_column_theme = "ë¯¸ë¶„ë¥˜"
        for tl in theme_locations:
            if (i * (img.shape[1]//4)) <= tl['x'] < ((i+1) * (img.shape[1]//4)):
                current_column_theme = tl['name']
                break

        h_sum = np.sum(thresh[:, c_start:c_end], axis=1)
        line_limit = np.mean(h_sum) * 0.4
        rows = []; in_line, start = False, 0
        for idx, val in enumerate(h_sum):
            if not in_line and val > line_limit: in_line, start = True, idx
            elif in_line and val < line_limit:
                if idx - start > 18: rows.append((start, idx))
                in_line = False

        for r_start, r_end in rows:
            chip = img_res[r_start-3:r_end+3, c_start:c_end]
            name_text = "".join(reader.readtext(chip[:, :int(chip.shape[1]*0.72)], detail=0))
            refined_stock = microscopic_correct_stock(name_text)
            if len(refined_stock) >= 2:
                mapping_result[refined_stock] = current_column_theme

    # --- 3. ìµœì¢… ì €ì¥ ---
    with open("mapping.json", "w", encoding="utf-8") as f:
        json.dump(mapping_result, f, ensure_ascii=False, indent=2)
    print(f"ğŸ¯ ì™„ë£Œ! {len(mapping_result)}ê°œ ì¢…ëª©ì´ ë§¤í•‘ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    run_integrated_analysis()
